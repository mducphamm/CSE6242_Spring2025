{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To effectively predict daily subway ridership in NYC, we explored a range of predictive models, encompassing both linear and non-linear approaches (RandomForest, RNN), to identify the algorithm that best captures the underlying patterns and maximizes predictive accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.gofplots import qqplot  \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from joblib import dump \n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and preprocessing data\n",
    "file_path = './cleaned_daily_ridership_weather_holi_data.csv'\n",
    "df = pd.read_csv(file_path, parse_dates=['date'])\n",
    "print('data shape: ', df.shape)\n",
    "# preparing trian and test datasets with scaled data\n",
    "X = df.drop(columns=['ridership', 'holidayName', 'date', 'weather_code', 'apparent_temperature_mean']) # dropping apparent_temp_mean because it highly correlates with temperature_2m_mean\n",
    "y = df['ridership']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# standardizing data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a dataframe to track the models and perforamnce scores\n",
    "model_comparison_df = pd.DataFrame(columns=['Model Name', 'RMSE', 'R-squared'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_y_pred = lr_model.predict(X_test_scaled)\n",
    "lr_mse = mean_squared_error(y_test, lr_y_pred)\n",
    "lr_r2 = r2_score(y_test, lr_y_pred)\n",
    "\n",
    "print(f\"R-squared: {lr_r2:.3f}\")\n",
    "lr_rmse = np.sqrt(lr_mse) \n",
    "print(f\"RMSE: {lr_rmse:.2f}\")\n",
    "print(f\"Mean Squared Error: {lr_mse:.2f}\")\n",
    "print(f\"Coefficients: {lr_model.coef_}\")\n",
    "print(f\"Intercept: {lr_model.intercept_:.2f}\")\n",
    "\n",
    "# extracting feature importance (coefficients)\n",
    "lr_feature_importance = pd.Series(lr_model.coef_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "# visualizing feature importance\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(lr_feature_importance)\n",
    "\n",
    "# Plot feature importance\n",
    "lr_feature_importance.plot(kind='bar', title=\"Feature Importance\")\n",
    "plt.ylabel(\"Coefficient Value\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.show()\n",
    "\n",
    "lr_results = {'Model Name': 'Linear Regression',\n",
    "              'RMSE': lr_rmse,\n",
    "              'R-squared': lr_r2}\n",
    "model_comparison_df = pd.concat([model_comparison_df, pd.Series(lr_results).to_frame().T], ignore_index=True)\n",
    "model_comparison_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns, index=X_train.index)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns, index=X_test.index)\n",
    "\n",
    "X_train_ols = sm.add_constant(X_train_scaled_df)\n",
    "X_test_ols = sm.add_constant(X_test_scaled_df)\n",
    "\n",
    "# Train the OLS model using statsmodels\n",
    "ols_model = sm.OLS(y_train, X_train_ols).fit()\n",
    "y_pred_ols = ols_model.predict(X_test_ols)\n",
    "\n",
    "mse_ols = mean_squared_error(y_test, y_pred_ols)\n",
    "r2_ols = r2_score(y_test, y_pred_ols)\n",
    "rmse_ols = np.sqrt(mse_ols)\n",
    "\n",
    "print(\"OLS Model Results:\")\n",
    "print(f\"R-squared: {r2_ols:.3f}\")\n",
    "print(f\"RMSE: {rmse_ols:.2f}\")\n",
    "print(f\"Mean Squared Error: {mse_ols:.2f}\")\n",
    "print(\"\\nModel Summary:\")\n",
    "print(ols_model.summary())\n",
    "\n",
    "# Extract feature importance (coefficients) and p-values\n",
    "coefficients = ols_model.params[1:] \n",
    "p_values = ols_model.pvalues[1:]    \n",
    "\n",
    "feature_importance_ols = pd.Series(coefficients, index=X_train_scaled_df.columns).sort_values(ascending=False)\n",
    "p_values_series = pd.Series(p_values, index=X_train_scaled_df.columns).sort_values()\n",
    "\n",
    "print(\"\\nFeature Importance (Coefficients):\")\n",
    "print(feature_importance_ols)\n",
    "\n",
    "print(\"\\nP-values:\")\n",
    "print(p_values_series.apply(lambda x: f\"{x:.3f}\"))\n",
    "\n",
    "# Plot feature importance (coefficients)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(feature_importance_ols.index, feature_importance_ols.values)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"OLS Feature Importance (Coefficients)\")\n",
    "plt.ylabel(\"Coefficient Value\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot p-values\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(p_values_series.index, p_values_series.values)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"OLS Feature P-values\")\n",
    "plt.ylabel(\"P-value\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.axhline(0.05, color='r', linestyle='--')\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can tell that some of the features have high p-values > 0.05, which might be considered less meaningful from statistical perspective. \n",
    "* shortwave_radiation_sum, precipitation_sum, wind_speed_10m_max, weather_categories_Precipitation (Light to Moderate), weather_categories_Clear or Fair Weather, precipitation_hours                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Regressions: Lasso, Ridge, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_regularized_models(X_train, y_train, X_test, y_test, feature_names, existing_df):\n",
    "    models = {\n",
    "        \"Ridge\": Ridge(),\n",
    "        \"Lasso\": Lasso(),\n",
    "        \"ElasticNet\": ElasticNet()\n",
    "    }\n",
    "\n",
    "    param_grids = {\n",
    "        \"Ridge\": {'alpha': [0.01, 0.1, 1, 10, 100]}, 'max_iter' : [10000],\n",
    "        \"Lasso\": {'alpha': [0.01, 0.1, 1, 10, 100]},\n",
    "        \"ElasticNet\": {'alpha': [0.01, 0.1, 1], 'l1_ratio': [0.1, 0.5, 0.9]}\n",
    "    }\n",
    "    results_list = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        # Hyperparameter tuning\n",
    "        grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='r2')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Predictions and metrics\n",
    "        y_pred_train = best_model.predict(X_train)\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "        mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "        mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "        r2_train = r2_score(y_train, y_pred_train)\n",
    "        r2_test = r2_score(y_test, y_pred_test)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"\\n{name} Model (Best Params: {grid_search.best_params_}):\")\n",
    "        print(f\"Overall R-squared: {r2:.3f}\")\n",
    "        print(f\"Training R-squared: {r2_train:.3f}\")\n",
    "        print(f\"Testing R-squared: {r2_test:.3f}\")\n",
    "        print(f\"Training RMSE: {np.sqrt(mse_train):.2f}\")\n",
    "        print(f\"Testing RMSE: {np.sqrt(mse_test):.2f}\")\n",
    "\n",
    "        # Feature importance (coefficients)\n",
    "        importance = pd.Series(best_model.coef_, index=feature_names).sort_values(ascending=False)\n",
    "        print(\"\\nFeature Importance (coefficients):\")\n",
    "        print(importance)\n",
    "\n",
    "        results_list.append({\n",
    "            'Model Name': name,\n",
    "            'RMSE': np.sqrt(mse_test),\n",
    "            'R-squared': r2_test,\n",
    "            'Best Params': grid_search.best_params_\n",
    "        })\n",
    "\n",
    "    # Append all results at once\n",
    "    updated_df = pd.concat([existing_df, pd.DataFrame(results_list)], ignore_index=True)\n",
    "    return updated_df\n",
    "\n",
    "feature_names = X.columns.to_list()\n",
    "model_comparison_df  = train_evaluate_regularized_models(X_train, y_train, X_test, y_test, feature_names, model_comparison_df)\n",
    "model_comparison_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not much improvement with Regularized regression. Next, we will train non-linear models to capture complex patterns not easily recognized by linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_evaluate_tree_models(X_train, y_train, X_test, y_test, feature_names, existing_df):\n",
    "    models = {\n",
    "        \"Decision Tree\": {\n",
    "            \"model\": DecisionTreeRegressor(random_state=42),\n",
    "            \"params\": {\n",
    "                'max_depth': [5, 7, 10],  # Limiting depth for interpretability\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 4],\n",
    "                'ccp_alpha': [0.01, 0.05, 0.1] # Pruning\n",
    "            }\n",
    "        },\n",
    "        \"Random Forest\": {\n",
    "            \"model\": RandomForestRegressor(random_state=42),\n",
    "            \"params\": {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'max_depth': [None, 10, 20],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [2, 4, 6]\n",
    "            }\n",
    "        },\n",
    "        \"Gradient Boosting\": {\n",
    "            \"model\": GradientBoostingRegressor(random_state=42),\n",
    "            \"params\": {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'learning_rate': [0.01, 0.1, 0.2],\n",
    "                'max_depth': [3, 4, 5],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [2, 4, 6]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    results_list = [] # initializing list to store model results\n",
    "    for name, model_info in models.items():\n",
    "        print(f\"\\nTuning {name}...\")\n",
    "        grid_search = GridSearchCV(model_info[\"model\"], model_info[\"params\"], cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred) # test mse\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        r2 = r2_score(y_test, y_pred) # test r2\n",
    "\n",
    "        print(f\"\\n{name} Model (Tuned):\")\n",
    "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Test Root Mean Squared Error: {rmse}\")\n",
    "        print(f\"Test Mean Squared Error: {mse}\")\n",
    "        print(f\"Test R-squared: {r2}\")\n",
    "\n",
    "        results_list.append({\n",
    "            'Model Name': name,\n",
    "            'RMSE': rmse,\n",
    "            'R-squared': r2,\n",
    "            'Best Params': grid_search.best_params_\n",
    "        })\n",
    "\n",
    "        print(f\"\\n Feature Importances: {best_model.feature_importances_}\")\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.barh(feature_names, best_model.feature_importances_, color='skyblue')\n",
    "        plt.xlabel(\"Feature Importance\")\n",
    "        plt.ylabel(\"Features\")\n",
    "        plt.title(\"Random Forest Feature Importances\")\n",
    "        plt.show()\n",
    "    updated_df = pd.concat([existing_df, pd.DataFrame(results_list)], ignore_index=True)\n",
    "    return updated_df\n",
    "\n",
    "feature_names = list(X.columns)\n",
    "model_comparison_df = tune_evaluate_tree_models(X_train, y_train, X_test, y_test, feature_names, model_comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So far, Random Forest has performed the considering high R-squared of 0.688 and low RMSE of 443,943."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA with Regression and RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA + Linear Regression with pipeline \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=9)),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred_pca_lr = pipeline.predict(X_test)\n",
    "mse_pca_lr = mean_squared_error(y_test, y_pred_pca_lr)\n",
    "r2_pca_lr = r2_score(y_test, y_pred_pca_lr)\n",
    "\n",
    "print(f\"\\nPCA Regression Model (Test performance):\")\n",
    "print(f\"PCA R-squared: {r2_pca_lr}\")\n",
    "print(f\"PCA Root Mean Squared Error: {np.sqrt(mse_pca_lr)}\")\n",
    "print(f\"\\nPCA Mean Squared Error: {mse_pca_lr}\")\n",
    "\n",
    "pca_lr_results = {'Model Name': 'PCA Regression',\n",
    "              'RMSE': np.sqrt(mse_pca_lr),\n",
    "              'R-squared': r2_pca_lr,\n",
    "              'Best Params': 'n_components = 9'}\n",
    "model_comparison_df = pd.concat([model_comparison_df, pd.Series(pca_lr_results).to_frame().T], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA + Random Forest\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# PCA with Random Forest Regressor in a pipeline\n",
    "pipeline_pca_rf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=9)),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))  # Using Random Forest Regressor\n",
    "])\n",
    "\n",
    "pipeline_pca_rf.fit(X_train, y_train)\n",
    "y_pred_pipeline_pca_rf = pipeline_pca_rf.predict(X_test)\n",
    "mse_pipeline_pca_rf = mean_squared_error(y_test, y_pred_pipeline_pca_rf)\n",
    "r2_pipeline_pca_rf = r2_score(y_test, y_pred_pipeline_pca_rf)\n",
    "rmse_pipeline_pca_rf = np.sqrt(mse_pipeline_pca_rf)\n",
    "\n",
    "print(f\"\\nPCA with Random Forest Regression Model (Test performance):\")\n",
    "print(f\"PCA + RF R-squared: {r2_pipeline_pca_rf}\")\n",
    "print(f\"PCA + RF Root Mean Squared Error: {rmse_pipeline_pca_rf}\")\n",
    "print(f\"PCA + RF Mean Squared Error: {mse_pipeline_pca_rf}\")\n",
    "\n",
    "# Comparing with Linear Regression PCA model\n",
    "print(f\"\\nPCA Regression Model (Test performance):\")\n",
    "print(f\"PCA R-squared: {r2_pipeline_pca_rf}\")\n",
    "print(f\"PCA Root Mean Squared Error: {np.sqrt(mse_pipeline_pca_rf)}\")\n",
    "print(f\"PCA Mean Squared Error: {mse_pipeline_pca_rf}\")\n",
    "\n",
    "pca_rf_results = {'Model Name': 'PCA RanfomForest',\n",
    "              'RMSE': np.sqrt(mse_pipeline_pca_rf),\n",
    "              'R-squared': r2_pipeline_pca_rf,\n",
    "              'Best Params': 'n_components = 9'}\n",
    "model_comparison_df = pd.concat([model_comparison_df, pd.Series(pca_rf_results).to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting XGBoost and Cat Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tunining using GridSearchCV\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating DMatrix for XGBoost for faster computation\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb.XGBRegressor(objective='reg:squarederror', seed=42),\n",
    "                           param_grid=param_grid, \n",
    "                           scoring='r2', \n",
    "                           cv=5, \n",
    "                           verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for XGBoost\n",
    "params_best = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.01,\n",
    "    'n_estimators': 500,\n",
    "    'min_child_weight': 10,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 1.0,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "xgb_regressor_best = xgb.XGBRegressor(**params_best)\n",
    "xgb_regressor_best.fit(X_train, y_train)\n",
    "y_pred_xgboost = xgb_regressor_best.predict(X_test)\n",
    "r2_xgboost = r2_score(y_test, y_pred_xgboost)\n",
    "mse_xgboost_reg = mean_squared_error(y_test, y_pred_xgboost)\n",
    "print(f\"R-squared: {r2_xgboost}\")\n",
    "print(f\"XGBoostRegressor Root Mean Squared Error: {np.sqrt(mse_xgboost_reg)}\")\n",
    "print(f\"XGBoostRegressor Mean Squared Error: {mse_xgboost_reg}\")\n",
    "\n",
    "feature_importance_xgboost = xgb_regressor_best.feature_importances_\n",
    "print(\"Feature Importances:\", feature_importance_xgboost)\n",
    "\n",
    "xgb_reg_results = {'Model Name': 'XGBoost Regressor',\n",
    "              'RMSE': np.sqrt(mse_xgboost_reg),\n",
    "              'R-squared': r2_xgboost,\n",
    "              'Best Params': grid_search.best_params_}\n",
    "model_comparison_df = pd.concat([model_comparison_df, pd.Series(xgb_reg_results).to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    X.columns.get_loc(\"weather_categories_Clear or Fair Weather\"),\n",
    "    X.columns.get_loc(\"weather_categories_Precipitation (Light to Moderate)\"),\n",
    "    X.columns.get_loc(\"weather_categories_Severe Weather\")\n",
    "]\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the CatBoost regressor\n",
    "catboost_regressor = CatBoostRegressor(\n",
    "    iterations=500,          # Number of trees\n",
    "    learning_rate=0.05,      # Step size for gradient descent\n",
    "    depth=6,                 # Tree depth (controls complexity)\n",
    "    # cat_features=categorical_features,  # Indices of categorical features\n",
    "    loss_function='RMSE',    # Root Mean Square Error for regression\n",
    "    verbose=100,             # Display training updates every 100 iterations\n",
    "    random_seed=42           # For reproducibility\n",
    ")\n",
    "\n",
    "catboost_regressor.fit(X_train, y_train, eval_set=(X_test, y_test), plot=True)\n",
    "y_pred_cat = catboost_regressor.predict(X_test)\n",
    "r2_cat = r2_score(y_test, y_pred_cat)\n",
    "mse_catboost_reg = mean_squared_error(y_test, y_pred_cat)\n",
    "print(f\"R-squared: {r2_cat}\")\n",
    "print(f\"catboost_regressor Root Mean Squared Error: {np.sqrt(mse_catboost_reg)}\")\n",
    "print(f\"catboost_regressor Mean Squared Error: {mse_catboost_reg}\")\n",
    "print(f\"R-squared: {r2_cat}\")\n",
    "\n",
    "# Feature Importance Analysis\n",
    "feature_importance_catboost = catboost_regressor.get_feature_importance(prettified=True)\n",
    "print(\"Feature Importances:\")\n",
    "print(feature_importance_catboost)\n",
    "\n",
    "catboost_reg_results = {'Model Name': 'CATBoost Regressor',\n",
    "              'RMSE': np.sqrt(mse_catboost_reg),\n",
    "              'R-squared': r2_cat,\n",
    "              'Best Params': {'iterations':500, 'learning_rate':0.05, 'depth':6, 'loss_function':'RMSE', 'verbose':100} }\n",
    "model_comparison_df = pd.concat([model_comparison_df, pd.Series(catboost_reg_results).to_frame().T], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with LSTM\n",
    "### We're considering fitting an RNN with LSTM because LSTMs, crucial for capturing long-term dependencies in time-series data, which standard RNNs often struggle with. While linear models can identify trends and correlations, and tree-based models can capture non-linear relationships, both often struggle to inherently understand the sequential nature of temporal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X_rnn = df.drop(columns=['ridership', 'holidayName', 'weather_code'])\n",
    "y = df['ridership'].values.astype(np.float32)\n",
    "\n",
    "# Extract temporal features\n",
    "X_rnn['year'] = df['date'].dt.year\n",
    "X_rnn['month'] = df['date'].dt.month\n",
    "X_rnn['day'] = df['date'].dt.day\n",
    "X_rnn['day_of_week'] = df['date'].dt.dayofweek\n",
    "X_rnn['day_of_week_sin'] = np.sin(2 * np.pi * X_rnn['day_of_week'] / 7)\n",
    "X_rnn['day_of_week_cos'] = np.cos(2 * np.pi * X_rnn['day_of_week'] / 7)\n",
    "X_rnn = X_rnn.drop(columns=['date']).values.astype(np.float32)\n",
    "\n",
    "# Scale features and target\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X_rnn)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping Class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.01):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "# Load dataset\n",
    "file_path = './cleaned_daily_ridership_weather_holi_data.csv'\n",
    "df = pd.read_csv(file_path, parse_dates=['date'])\n",
    "\n",
    "# Prepare features and target\n",
    "X_rnn = df.drop(columns=['ridership', 'holidayName', 'weather_code'])\n",
    "y = df['ridership'].values.astype(np.float32)\n",
    "\n",
    "# Extract temporal features\n",
    "X_rnn['year'] = df['date'].dt.year\n",
    "X_rnn['month'] = df['date'].dt.month\n",
    "X_rnn['day'] = df['date'].dt.day\n",
    "X_rnn['day_of_week'] = df['date'].dt.dayofweek\n",
    "X_rnn['day_of_week_sin'] = np.sin(2 * np.pi * X_rnn['day_of_week'] / 7)\n",
    "X_rnn['day_of_week_cos'] = np.cos(2 * np.pi * X_rnn['day_of_week'] / 7)\n",
    "X_rnn = X_rnn.drop(columns=['date']).values.astype(np.float32)\n",
    "\n",
    "# Scale features and target\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X_rnn)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Chronological train-test split\n",
    "test_size = 0.2\n",
    "split_idx = int(len(X_scaled) * (1 - test_size))\n",
    "X_train, X_test = X_scaled[:split_idx], X_scaled[split_idx:]\n",
    "y_train, y_test = y_scaled[:split_idx], y_scaled[split_idx:]\n",
    "\n",
    "# Chronological validation split\n",
    "val_size = 0.2\n",
    "val_split_idx = int(len(X_train) * (1 - val_size))\n",
    "X_train_final, X_val = X_train[:val_split_idx], X_train[val_split_idx:]\n",
    "y_train_final, y_val = y_train[:val_split_idx], y_train[val_split_idx:]\n",
    "\n",
    "# Custom Dataset\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y, seq_length):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) - self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X[idx:idx+self.seq_length], \n",
    "                self.y[idx+self.seq_length])\n",
    "\n",
    "# LSTM Model with Modified Architecture\n",
    "class RidershipLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.2):\n",
    "        super(RidershipLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, \n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.fc2 = nn.Linear(hidden_size // 2, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.dropout(out[:, -1, :])  # Take the last hidden state\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        return self.fc2(out)\n",
    "\n",
    "# Parameters\n",
    "seq_length = 30\n",
    "input_size = X_scaled.shape[1]\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "batch_size = 32\n",
    "n_epochs = 100\n",
    "\n",
    "# Datasets and DataLoaders\n",
    "train_dataset = TimeSeriesDataset(X_train_final, y_train_final, seq_length)\n",
    "val_dataset = TimeSeriesDataset(X_val, y_val, seq_length)\n",
    "test_dataset = TimeSeriesDataset(X_test, y_test, seq_length)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "model = RidershipLSTM(input_size, hidden_size, num_layers, output_size, dropout=0.3)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "early_stopping = EarlyStopping(patience=10, delta=0.01)\n",
    "\n",
    "# Training loop with early stopping\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in tqdm(range(n_epochs), desc=\"Training\"):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            outputs = model(X_batch)\n",
    "            epoch_val_loss += criterion(outputs, y_batch.unsqueeze(1)).item()\n",
    "    \n",
    "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "    avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    \n",
    "    scheduler.step(avg_val_loss)\n",
    "    early_stopping(avg_val_loss)\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label='Training Loss', color='blue', linewidth=2)\n",
    "plt.plot(val_losses, label='Validation Loss', color='red', linewidth=2)\n",
    "plt.title(\"Training & Validation Loss Curves\", fontsize=14)\n",
    "plt.xlabel(\"Epochs\", fontsize=12)\n",
    "plt.ylabel(\"MSE Loss\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on Test Set\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        preds = model(X_batch)\n",
    "        test_preds.extend(preds.squeeze().numpy())\n",
    "        test_true.extend(y_batch.numpy())\n",
    "\n",
    "# Inverse scaling\n",
    "test_preds_rescaled = scaler_y.inverse_transform(np.array(test_preds).reshape(-1, 1))\n",
    "test_true_rescaled = scaler_y.inverse_transform(np.array(test_true).reshape(-1, 1))\n",
    "\n",
    "# Calculate metrics\n",
    "final_rmse = np.sqrt(mean_squared_error(test_true_rescaled, test_preds_rescaled))\n",
    "final_r2 = r2_score(test_true_rescaled, test_preds_rescaled)\n",
    "\n",
    "print(f\"\\nFINAL MODEL TEST SET PERFORMANCE:\")\n",
    "print(f\"RMSE: {final_rmse:.2f}\")\n",
    "print(f\"R²: {final_r2:.4f}\")\n",
    "\n",
    "RNN_LSTM_reg_results = {'Model Name': 'RNN LSTM',\n",
    "              'RMSE': final_rmse,\n",
    "              'R-squared': final_r2,\n",
    "              'Best Params': {'seq_length': 30, 'hidden_size': 128, 'num_layer' : 2, 'output_size': 1,'batch_size':32,'n_epochs':100}}\n",
    "model_comparison_df = pd.concat([model_comparison_df, pd.Series(RNN_LSTM_reg_results).to_frame().T], ignore_index=True)\n",
    "\n",
    "# Plot Predictions vs Actual\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(test_true_rescaled, label='Actual', color='blue', alpha=0.7, linewidth=2)\n",
    "plt.plot(test_preds_rescaled, label='Predicted', color='red', alpha=0.7, linewidth=1.5)\n",
    "plt.title(f\"Test Set Performance\\nRMSE: {final_rmse:.2f}, R²: {final_r2:.4f}\", fontsize=14)\n",
    "plt.xlabel(\"Time Step\", fontsize=12)\n",
    "plt.ylabel(\"Ridership\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Residual Plot\n",
    "residuals = test_true_rescaled - test_preds_rescaled\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(test_preds_rescaled, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title(\"Residual Plot\", fontsize=14)\n",
    "plt.xlabel(\"Predicted Values\", fontsize=12)\n",
    "plt.ylabel(\"Residuals (Actual - Predicted)\", fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# # Save the final model\n",
    "# torch.save(model.state_dict(), 'ridership_lstm_final.pth')\n",
    "# print(\"Final model saved to ridership_lstm_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction test on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "new_date = datetime.date(2025, 7, 1)  # Hypothetical future date\n",
    "day_of_week = new_date.weekday()\n",
    "\n",
    "synthetic_row = {\n",
    "\n",
    "    'temperature_2m_mean': 70, \n",
    "    'temp_2m_range': 10,\n",
    "    'apparent_temperature_mean': 71,\n",
    "    'apparent_temp_range': 9.229394,\n",
    "    'daylight_duration': 55520,\n",
    "    'sunshine_duration':27307.883, \n",
    "    'precipitation_sum': 0.003937,\n",
    "    'snowfall_sum': 0,\n",
    "    'precipitation_hours': 1,\n",
    "    'wind_speed_10m_max': 11.887713,\n",
    "    'wind_direction_10m_dominant': 113.585045,\n",
    "    'shortwave_radiation_sum': 15.16,\n",
    "    'weekend': 1,\n",
    "    'is_holiday': 0, \n",
    "    'weather_categories_Clear or Fair Weather': 0,\n",
    "    'weather_categories_Precipitation (Light to Moderate)': 1,\n",
    "    'weather_categories_Severe Weather': 0,\n",
    "    # Add temporal features\n",
    "    'year': new_date.year,\n",
    "    'month': new_date.month,\n",
    "    'day': new_date.day,\n",
    "    'day_of_week': day_of_week,\n",
    "    'day_of_week_sin': np.sin(2 * np.pi * day_of_week / 7),\n",
    "    'day_of_week_cos': np.cos(2 * np.pi * day_of_week / 7)\n",
    "}\n",
    "\n",
    "# Convert to DataFrame and scale the features\n",
    "synthetic_df = pd.DataFrame([synthetic_row])\n",
    "synthetic_scaled = scaler_X.transform(synthetic_df)\n",
    "\n",
    "# Combine with the last 29 days from the test set to form a sequence\n",
    "last_29_days = X_test[-(seq_length - 1):]  # Use the last 29 rows from the test data\n",
    "synthetic_sequence = np.vstack([last_29_days, synthetic_scaled]).astype(np.float32)\n",
    "\n",
    "# Convert to tensor for the LSTM model\n",
    "synthetic_sequence_tensor = torch.tensor(synthetic_sequence).unsqueeze(0)  \n",
    "\n",
    "# Make the prediction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    synthetic_prediction_scaled = model(synthetic_sequence_tensor).numpy()\n",
    "\n",
    "# Rescale the prediction back to the original scale\n",
    "synthetic_prediction = scaler_y.inverse_transform(synthetic_prediction_scaled)\n",
    "\n",
    "print(f\"Predicted Ridership for {new_date}: {synthetic_prediction[0][0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Use of temporal features such as day of the week yielded better result for RNN + LSTM. Let's explore using such features on our Linear and Tree based models too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X_temporal_features = df.drop(columns=['ridership', 'holidayName', 'weather_code', 'apparent_temperature_mean', 'precipitation_hours'])\n",
    "y = df['ridership'].values.astype(np.float32)\n",
    "\n",
    "# Extract temporal features\n",
    "# X_temporal_features['year'] = df['date'].dt.year\n",
    "X_temporal_features['month'] = df['date'].dt.month\n",
    "X_temporal_features['day'] = df['date'].dt.day\n",
    "X_temporal_features['day_of_week'] = df['date'].dt.dayofweek\n",
    "X_temporal_features['day_of_week_sin'] = np.sin(2 * np.pi * X_temporal_features['day_of_week'] / 7)\n",
    "X_temporal_features['day_of_week_cos'] = np.cos(2 * np.pi * X_temporal_features['day_of_week'] / 7)\n",
    "# X_temporal_features = X_temporal_features.drop(columns=['date']).values.astype(np.float32)\n",
    "X_temporal_features = X_temporal_features.drop(columns=['date']) #.values.astype(np.float32)\n",
    "# standardizing data\n",
    "scaler = StandardScaler()\n",
    "X_scaled_temoral_features = scaler.fit_transform(X_temporal_features)\n",
    "\n",
    "# Split data\n",
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(X_scaled_temoral_features, y, test_size=0.3, random_state=42)\n",
    "X_temporal_features.head()\n",
    "\n",
    "# Save fitted scaler, which will be helpful during predictin scoring\n",
    "scaler_filename = \"./scaler_temporal_features.pkl\"\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "print(f\"Scaler for temporal features saved to: {scaler_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training linear model with temporal features\n",
    "# standardizing data\n",
    "scaler_lr = StandardScaler()\n",
    "x_temp_feat_lr = X_temporal_features.drop(columns=['month', 'day', 'day_of_week_sin', 'day_of_week_cos'])\n",
    "X_scaled_temoral_lr = scaler_lr.fit_transform(x_temp_feat_lr)\n",
    "\n",
    "# Split data\n",
    "X_train_tf_lr, X_test_tf_lr, y_train_tf_lr, y_test_tf_lr = train_test_split(X_scaled_temoral_lr, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_tf_lr, y_train_tf_lr)\n",
    "y_pred_lr = model.predict(X_test_tf_lr)\n",
    "mse_lr = mean_squared_error(y_test_tf_lr, y_pred_lr)\n",
    "r2_lr = r2_score(y_test_tf_lr, y_pred_lr)\n",
    "\n",
    "# joblib.dump(model, './linear_regression_model.pkl')\n",
    "\n",
    "print(f\"R-squared: {r2_lr:.3f}\")\n",
    "rmse_lr = np.sqrt(mse_lr) \n",
    "print(f\"RMSE: {rmse_lr:.2f}\")\n",
    "print(f\"Mean Squared Error: {mse_lr:.2f}\")\n",
    "print(f\"Coefficients: {model.coef_}\")\n",
    "print(f\"Intercept: {model.intercept_:.2f}\")\n",
    "results_list = []\n",
    "results_list.append({\n",
    "    'Model Name': f'Linear Regression + temporal_features',\n",
    "    'RMSE': rmse_lr,\n",
    "    'R-squared': r2_lr,\n",
    "    'Best Params': None\n",
    "})\n",
    "\n",
    "# Append all results at once\n",
    "model_comparison_df = pd.concat([model_comparison_df, pd.DataFrame(results_list)], ignore_index=True)\n",
    "\n",
    "# extracting feature importance (coefficients)\n",
    "feature_importance = pd.Series(model.coef_, index=x_temp_feat_lr.columns).sort_values(ascending=False)\n",
    "\n",
    "# visualizing feature importance\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Plot feature importance\n",
    "feature_importance.plot(kind='bar', title=\"Feature Importance\")\n",
    "plt.ylabel(\"Coefficient Value\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not much difference. Temporal elements mightly add more multicollinearity since month, day of week, day, day of week sin/cos, are related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Linear Regression with OLS for P-Values and better interpretations\n",
    "\n",
    "# Convert scaled arrays back to DataFrames with original column names\n",
    "X_train_scaled_df = pd.DataFrame(X_train_tf_lr, columns=x_temp_feat_lr.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_tf_lr, columns=x_temp_feat_lr.columns)\n",
    "\n",
    "# Add a constant term to the independent variables\n",
    "X_train_ols = sm.add_constant(X_train_scaled_df)\n",
    "X_test_ols = sm.add_constant(X_test_scaled_df)\n",
    "\n",
    "# Train the OLS model using statsmodels\n",
    "ols_model = sm.OLS(y_train_tf, X_train_ols).fit()\n",
    "\n",
    "# Make predictions\n",
    "y_pred_ols = ols_model.predict(X_test_ols)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_ols = mean_squared_error(y_test_tf, y_pred_ols)\n",
    "r2_ols = r2_score(y_test_tf, y_pred_ols)\n",
    "rmse_ols = np.sqrt(mse_ols)\n",
    "\n",
    "print(\"OLS Model Results:\")\n",
    "print(f\"R-squared: {r2_ols:.3f}\")\n",
    "print(f\"RMSE: {rmse_ols:.2f}\")\n",
    "print(f\"Mean Squared Error: {mse_ols:.2f}\")\n",
    "print(\"\\nModel Summary:\")\n",
    "print(ols_model.summary())\n",
    "\n",
    "# Extract feature importance (coefficients) and p-values\n",
    "coefficients = ols_model.params[1:]  # Exclude the constant term\n",
    "p_values = ols_model.pvalues[1:]     # Exclude the constant term\n",
    "\n",
    "feature_importance_ols = pd.Series(coefficients, index=X_train_scaled_df.columns).sort_values(ascending=False)\n",
    "p_values_series = pd.Series(p_values, index=X_train_scaled_df.columns).sort_values()\n",
    "\n",
    "print(\"\\nFeature Importance (Coefficients):\")\n",
    "print(feature_importance_ols)\n",
    "\n",
    "print(\"\\nP-values:\")\n",
    "print(p_values_series.apply(lambda x: f\"{x:.3f}\"))\n",
    "\n",
    "# Plot feature importance (coefficients)\n",
    "feature_importance_ols.plot(kind='bar', title=\"OLS Feature Importance (Coefficients)\")\n",
    "plt.ylabel(\"Coefficient Value\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.show()\n",
    "\n",
    "# Plot p-values\n",
    "plt.figure()\n",
    "p_values_series.plot(kind='bar', title=\"OLS Feature P-values\")\n",
    "plt.ylabel(\"P-value\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.axhline(0.05, color='r', linestyle='--') # Significance threshold\n",
    "plt.yticks(np.arange(0, 1.1, 0.1)) # Ensure y-axis shows values from 0 to 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularized Regression + Hyper parameter Tuining\n",
    "def train_evaluate_regularized_models(X_train, y_train, X_test, y_test, feature_names, existing_df):\n",
    "    models = {\n",
    "        \"Ridge\": Ridge(),\n",
    "        \"Lasso\": Lasso(),\n",
    "        \"ElasticNet\": ElasticNet()\n",
    "    }\n",
    "\n",
    "    param_grids = {\n",
    "        \"Ridge\": {'alpha': [0.01, 0.1, 1, 10, 100]}, 'max_iter' : [10000],\n",
    "        \"Lasso\": {'alpha': [0.01, 0.1, 1, 10, 100]},\n",
    "        \"ElasticNet\": {'alpha': [0.01, 0.1, 1], 'l1_ratio': [0.1, 0.5, 0.9]}\n",
    "    }\n",
    "    results_list = []\n",
    "    for name, model in models.items():\n",
    "        # Hyperparameter tuning\n",
    "        grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='r2')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Predictions and metrics\n",
    "        y_pred_train = best_model.predict(X_train)\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "        mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "        mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "        r2_train = r2_score(y_train, y_pred_train)\n",
    "        r2_test = r2_score(y_test, y_pred_test)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"\\n{name} Model (Best Params: {grid_search.best_params_}):\")\n",
    "        print(f\"Overall R-squared: {r2:.3f}\")\n",
    "        print(f\"Training R-squared: {r2_train:.3f}\")\n",
    "        print(f\"Testing R-squared: {r2_test:.3f}\")\n",
    "        print(f\"Training RMSE: {np.sqrt(mse_train):.2f}\")\n",
    "        print(f\"Testing RMSE: {np.sqrt(mse_test):.2f}\")\n",
    "\n",
    "        # Feature importance (coefficients)\n",
    "        importance = pd.Series(best_model.coef_, index=feature_names).sort_values(ascending=False)\n",
    "        print(\"\\nFeature Importance (coefficients):\")\n",
    "        print(importance)\n",
    "    \n",
    "        results_list.append({\n",
    "            'Model Name': f'{name} + temporal_features',\n",
    "            'RMSE': np.sqrt(mse_test),\n",
    "            'R-squared': r2_test,\n",
    "            'Best Params': grid_search.best_params_\n",
    "        })\n",
    "\n",
    "    # Append all results at once\n",
    "    updated_df = pd.concat([existing_df, pd.DataFrame(results_list)], ignore_index=True)\n",
    "    return updated_df\n",
    "\n",
    "\n",
    "feature_names = X_temporal_features.columns.to_list()\n",
    "model_comparison_df = train_evaluate_regularized_models(X_train_tf, y_train_tf, X_test_tf, y_test_tf, feature_names, model_comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison_df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retraining Tree based models using Temporal features such as day of week, month, day, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree Based models\n",
    "def tune_evaluate_tree_models(X_train, y_train, X_test, y_test, feature_names, existing_df):\n",
    "    models = {\n",
    "        \"Decision Tree\": {\n",
    "            \"model\": DecisionTreeRegressor(random_state=42),\n",
    "            \"params\": {\n",
    "                'max_depth': [5, 7, 10],  # Limiting depth for interpretability\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 4],\n",
    "                'ccp_alpha': [0.01, 0.05, 0.1] # Pruning\n",
    "            }\n",
    "        },\n",
    "        \"Random Forest\": {\n",
    "            \"model\": RandomForestRegressor(random_state=42),\n",
    "            \"params\": {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'max_depth': [None, 10, 20],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [2, 4, 6]\n",
    "            }\n",
    "        },\n",
    "        \"Gradient Boosting\": {\n",
    "            \"model\": GradientBoostingRegressor(random_state=42),\n",
    "            \"params\": {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'learning_rate': [0.01, 0.1, 0.2],\n",
    "                'max_depth': [3, 4, 5],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [2, 4, 6]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    results_list = []\n",
    "    for name, model_info in models.items():\n",
    "        print(f\"\\nTuning {name}...\")\n",
    "        grid_search = GridSearchCV(model_info[\"model\"], model_info[\"params\"], cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"\\n{name} Model (Tuned):\")\n",
    "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Test Root Mean Squared Error: {rmse}\")\n",
    "        print(f\"Test Mean Squared Error: {mse}\")\n",
    "        print(f\"Test R-squared: {r2}\")\n",
    "        \n",
    "        results_list.append({\n",
    "            'Model Name': f'{name} + temporal_features',\n",
    "            'RMSE': rmse,\n",
    "            'R-squared': r2,\n",
    "            'Best Params': grid_search.best_params_\n",
    "        })\n",
    "\n",
    "        if name == \"Random Forest\":\n",
    "            joblib.dump(best_model, \"./best_random_forest_model.pkl\")\n",
    "            print(\"\\nBest RandomForest model saved as 'best_random_forest_model.pkl'\")\n",
    "\n",
    "        print(f\"\\n Feature Importances: {best_model.feature_importances_}\")\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.barh(feature_names, best_model.feature_importances_, color='skyblue')\n",
    "        plt.xlabel(\"Feature Importance\")\n",
    "        plt.ylabel(\"Features\")\n",
    "        plt.title(\"Random Forest Feature Importances\")\n",
    "        plt.show()\n",
    "    updated_df = pd.concat([existing_df, pd.DataFrame(results_list)], ignore_index=True)\n",
    "    return updated_df\n",
    "feature_names = X_temporal_features.columns.to_list()\n",
    "model_comparison_df = tune_evaluate_tree_models(X_train_tf, y_train_tf, X_test_tf, y_test_tf, feature_names, model_comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATBoost with additional Temporal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    X.columns.get_loc(\"weather_categories_Clear or Fair Weather\"),\n",
    "    X.columns.get_loc(\"weather_categories_Precipitation (Light to Moderate)\"),\n",
    "    X.columns.get_loc(\"weather_categories_Severe Weather\")\n",
    "]\n",
    "\n",
    "# Initialize the CatBoost regressor\n",
    "catboost_regressor = CatBoostRegressor(\n",
    "    iterations=500,          # Number of trees\n",
    "    learning_rate=0.05,      # Step size for gradient descent\n",
    "    depth=6,                 # Tree depth (controls complexity)\n",
    "    # cat_features=categorical_features,  # Indices of categorical features\n",
    "    loss_function='RMSE',    # Root Mean Square Error for regression\n",
    "    verbose=100,             # Display training updates every 100 iterations\n",
    "    random_seed=42           # For reproducibility\n",
    ")\n",
    "\n",
    "\n",
    "catboost_regressor.fit(X_train_tf, y_train_tf, eval_set=(X_test_tf, y_test_tf), plot=True)\n",
    "y_pred_catb = catboost_regressor.predict(X_test_tf)\n",
    "r2_cat = r2_score(y_test_tf, y_pred_catb)\n",
    "mse_cat = mean_squared_error(y_test_tf, y_pred_catb)\n",
    "rmse_cat = np.sqrt(mse_cat)\n",
    "print(f\"R-squared: {r2_cat}\")\n",
    "print(f\"RMSE: {rmse_cat}\")\n",
    "\n",
    "catboost_reg_results = {'Model Name': 'CATBoost Regressor + temporal_features',\n",
    "              'RMSE': rmse_cat,\n",
    "              'R-squared': r2_cat,\n",
    "              'Best Params': {'iterations':500, 'learning_rate':0.05, 'depth':6, 'loss_function':'RMSE', 'verbose':100} }\n",
    "model_comparison_df = pd.concat([model_comparison_df, pd.Series(catboost_reg_results).to_frame().T], ignore_index=True)\n",
    "# Feature Importance Analysis\n",
    "feature_importance_catboost = catboost_regressor.get_feature_importance(prettified=True)\n",
    "print(\"Feature Importances:\")\n",
    "print(feature_importance_catboost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL MODELS COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_result_df = model_comparison_df.sort_values(by=['R-squared', 'RMSE', 'Model Name'],\n",
    "                                            ascending=[False, True, True])\n",
    "\n",
    "sorted_result_df.to_csv('Models Result Comparison.csv', index=False)\n",
    "print(\"Models Result Comparison exported to predicted_data.csv\\n\")\n",
    "\n",
    "print(\"Sorted Model Performance:\")\n",
    "sorted_result_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearly, Randfom Forest with temporal features outperformed other models based on high R-Squared of 0.748 and RMSE 398,865. We will use the Random Forest model for Predction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test runnig the Random forest model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temporal_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This chunk of code laods the model, preprocess the input data, and spits out the Daily NYC Ridership Prediction\n",
    "def preprocess_date(df):\n",
    "    # Preprocesses the date feature by extracting relevant components.\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "    df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "\n",
    "    df = df.drop('date', axis=1)\n",
    "    return df\n",
    "\n",
    "def load_model_and_scaler(model_path, scaler_path):\n",
    "    # Loads the trained model and scaler from the specified file paths.\n",
    "    try:\n",
    "        with open(model_path, 'rb') as file:\n",
    "            model = joblib.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Model file not found at {model_path}\")\n",
    "        model = None\n",
    "\n",
    "    try:\n",
    "        with open(scaler_path, 'rb') as file:\n",
    "            scaler = joblib.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Scaler file not found at {scaler_path}\")\n",
    "        scaler = None\n",
    "\n",
    "    return model, scaler\n",
    "\n",
    "def preprocess_features(data, scaler):\n",
    "    # Preprocesses the input features using the loaded scaler.\n",
    "    if scaler is None:\n",
    "        print(\"Error: Scaler not loaded. Cannot preprocess features.\")\n",
    "        return None\n",
    "    scaled_data = scaler.transform(data)\n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "    return scaled_df\n",
    "\n",
    "def make_prediction(model, preprocessed_data):\n",
    "    # Makes predictions using the loaded model and preprocessed data.\n",
    "    if model is None:\n",
    "        print(\"Error: Model not loaded. Cannot make predictions.\")\n",
    "        return None\n",
    "    predictions = model.predict(preprocessed_data)\n",
    "    return predictions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_file_path = 'best_random_forest_model.pkl' \n",
    "    scaler_file_path = 'scaler_temporal_features.pkl' \n",
    "\n",
    "    # Load the model and scaler\n",
    "    loaded_model, loaded_scaler = load_model_and_scaler(model_file_path, scaler_file_path)\n",
    "\n",
    "    if loaded_model and loaded_scaler:\n",
    "        # --- Get input data for prediction ---\n",
    "        input_data = { # This input data will be coming from the FRONT END USER INTERACTION\n",
    "            'date': ['2025-04-15'],  \n",
    "            'temperature_2m_mean': [15.0],\n",
    "            'daylight_duration': [13.5],\n",
    "            'sunshine_duration': [10.0],\n",
    "            'precipitation_sum': [0.0],\n",
    "            'snowfall_sum': [0.0],\n",
    "            'wind_speed_10m_max': [5.0],\n",
    "            'wind_direction_10m_dominant': [270],\n",
    "            'shortwave_radiation_sum': [20.0],\n",
    "            'weekend': [1],\n",
    "            'is_holiday': [1],\n",
    "            'apparent_temp_range': [10.0],\n",
    "            'temp_2m_range': [8.0],\n",
    "            'weather_categories_Clear or Fair Weather': [1],\n",
    "            'weather_categories_Precipitation (Light to Moderate)': [0],\n",
    "            'weather_categories_Severe Weather': [0]\n",
    "            #'month', 'day', 'day_of_week', 'day_of_week_sin', 'day_of_week_cos' will be generated from the 'date' column \n",
    "            # using preprocess_date()\n",
    "            \n",
    "        }\n",
    "        input_df = pd.DataFrame(input_data)\n",
    "\n",
    "        # Preprocess the date temproal feature ---\n",
    "        input_df_processed_date = preprocess_date(input_df.copy())\n",
    "\n",
    "        # Select the features that were used for training. Very import to have the same order of columns that was used for RandomForest training\n",
    "        feature_columns_to_scale = [\n",
    "            'temperature_2m_mean', 'daylight_duration', 'sunshine_duration',\n",
    "            'precipitation_sum', 'snowfall_sum', 'wind_speed_10m_max',\n",
    "            'wind_direction_10m_dominant', 'shortwave_radiation_sum', 'weekend',\n",
    "            'is_holiday', 'apparent_temp_range', 'temp_2m_range',\n",
    "            'weather_categories_Clear or Fair Weather',\n",
    "            'weather_categories_Precipitation (Light to Moderate)',\n",
    "            'weather_categories_Severe Weather', 'month', 'day', 'day_of_week',\n",
    "            'day_of_week_sin', 'day_of_week_cos'\n",
    "        ]\n",
    "\n",
    "        # Ensure all required columns are present\n",
    "        if all(col in input_df_processed_date.columns for col in feature_columns_to_scale):\n",
    "            input_df_for_scaling = input_df_processed_date[feature_columns_to_scale]\n",
    "\n",
    "            # Preprocess and scale all features using the loaded scaler that was used for model training\n",
    "            scaled_features_df = preprocess_features(input_df_for_scaling, loaded_scaler)\n",
    "\n",
    "            if scaled_features_df is not None:\n",
    "                # Make the prediction \n",
    "                prediction = make_prediction(loaded_model, scaled_features_df)\n",
    "\n",
    "                if prediction is not None:\n",
    "                    print(\"Daily NYC Subway Ridership Prediction:\", prediction)\n",
    "                else:\n",
    "                    print(\"Prediction failed.\")\n",
    "            else:\n",
    "                print(\"Feature scaling failed.\")\n",
    "        else:\n",
    "            print(\"Error: Not all required features are present in the input data.\")\n",
    "            missing_features = [col for col in feature_columns_to_scale if col not in input_df_processed_date.columns]\n",
    "            print(\"Missing features:\", missing_features)\n",
    "\n",
    "    else:\n",
    "        print(\"Failed to load model or scaler.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse6242",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
